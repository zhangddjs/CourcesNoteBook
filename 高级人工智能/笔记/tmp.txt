感知机，猜对奖励，猜错惩罚。
只能解决线性可分问题，但不能解决非线性问题(XOR issue)。
解决非线性需要多层协作。

支撑向量机.

不能线性可分，到高维可以，则还是线性可分。

imagenet 图片数据库。

训练集结果很好，但测试集不行 -- 过学习

模式分类： 数据采集->特征选取->模型选择->训练和测试->复杂度分析、反馈。


判别函数
n维：d(x) = w_0^T + w_n+1
增广模式向量，增广权向量。
d(x) > 0 第1类， < 0 第2类。 （二分类）
m分类：属于第i类，不属于第i类。 只有d_i(X) > 0，其它d(x) < 0，属于第i类。
分类图

分段线性-垂直平分线

重点-多类情况3种 判别方法。

习题


权向量-分类超平面法向量
法向量W_0，单位法向量W_0 / ||W_0||
判别函数d(X) 正比于点X到超平面的代数距离。
模式空间分两半，一半大于0，一半小于0
权空间
模式空间
解域：正向的交集

分类器形式->函数->求解

Fisher线性判别：高维不好分，降维好分。进行降维。
映射到一维->权值，投影
d维到1维的一般数学变换方法。
1维、d维 类内离散度矩阵、类间离散度矩阵 y空间波浪号
Fisher准则函数，J越大越好(分子越大越好，分母越小越好，为什么)
Lagrange算法-

感知器算法
初始权向量w(1), 分类正确w(k+1)=w(k)（奖励），分类错误w(k+1)=w(k) +/- Cx_k (惩罚)
最终形式
案例：增广，规范化，任取权值为0向量，c=1，
多类情况
迭代直到所有分类都正确。
感知器动态展示.

可训练的确定性分类器的迭代法
梯度法，基本思想，初始权向量w(1)，推导出的最终公式，学习率，w(k+1)=w(k)-C*tidu
运用到感知机算法。wT*x 大于0 为0， 否则。 sign函数。
最小平方误差(LMSE)算法。对可分模式可以求解，否则给出参数。e(k)确定是否继续迭代。

支持向量机
样本线性可分有多个线，最优分类超平面。
(wT*x) + b >= 1 第一类，<= -1 第二类 (原本是0)
x1 离 1 超平面最近的向量，x2 离 -1 超平面最近的向量（样本）。得到投影（黑线）
目标函数 min_w,b 1/2 * ||w||^2, y_i[(w*xi)+b]-1 >= 0
拉格朗日系数，等价问题。
迭代算法alpha, w, b求解。
找出支撑向量，满足一定条件，即离分类超平面最近的样本(函数值是1或-1)。
线性不可分情况 引入非负松弛变量 wx+b <= -1+kesi 表示一部分xx到了oo部分，但在这个范围内。松弛量越少越好。
广义最优分类面。
最优判别函数。

猫-模板-矩阵和模板相乘最大，则是猫。
卷积。
模板需要学习。
模板的可视化解释（比如马，学出来可能是两头的马，因为数据库中可能有朝左的也有朝右的）

大间隔和推广能力
期望风险()，经验风险，统计学习理论关键结论。界R(w) h VC维

重点 感知器，怎么迭代；支持向量机(线性SVM), 支持向量怎么找，超平面怎么确定，怎么分类，可视化。

习题-p107；习题感知器迭代。






